# image-token-llm-pretrained Ollama Bundle

Artifacts generated by `ImageTokenReasoningLLM.`
export_ollama_bundle`.

1. Start the compatible server:
   uvicorn image_token_llm.ollama_adapter:app --host 0.0.0.0
   --port 8000
2. Point the Ollama CLI to it: 
   export OLLAMA_HOST=http://localhost:8000
3. The serialized weights live at `image-token-llm-pretrained_weights.pt`.
4. Tokenizer + config files mirror the runtime state for reproducibility.
