<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1600 2800">
  <defs>
    <style>
      .title { font: bold 26px sans-serif; fill: #000000; }
      .subtitle { font: bold 18px sans-serif; fill: #000000; }
      .label { font: 14px sans-serif; fill: #000000; }
      .formula { font: 11px monospace; fill: #1a1a1a; }
      .note { font: 11px sans-serif; fill: #004d40; font-style: italic; }
      .improvement { font: bold 10px sans-serif; fill: #4a148c; }
      .box { fill: #f5f5f5; stroke: #34495e; stroke-width: 2; }
      .component { fill: #bbdefb; stroke: #1976d2; stroke-width: 2; }
      .expert { fill: #ffcdd2; stroke: #c62828; stroke-width: 2; }
      .graph { fill: #c8e6c9; stroke: #388e3c; stroke-width: 2; }
      .rl { fill: #ffe0b2; stroke: #f57c00; stroke-width: 2; }
      .new { fill: #e1bee7; stroke: #6a1b9a; stroke-width: 2; }
      .arrow { fill: none; stroke: #424242; stroke-width: 2; marker-end: url(#arrowhead); }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="#7f8c8d" />
    </marker>
  </defs>
  
  <!-- Title -->
  <text x="800" y="40" text-anchor="middle" class="title">Dreaming-Based Reasoning LLM - v2.0</text>
  <text x="800" y="65" text-anchor="middle" class="note">With Advanced MoE, Graph Transformers, PPO, and Extended Context</text>
  
  <!-- ============ SECTION 1: INPUT LAYER ============ -->
  <g id="input-layer">
    <rect x="50" y="100" width="1500" height="220" class="component" rx="5"/>
    <text x="800" y="125" text-anchor="middle" class="subtitle">1. Input Tokenizer (IMPROVED)</text>
    
    <!-- Text Path with Contrastive Loss -->
    <rect x="100" y="150" width="350" height="150" class="new" rx="3"/>
    <text x="275" y="175" text-anchor="middle" class="label">Text Path (+ Contrastive)</text>
    <text x="275" y="195" text-anchor="middle" class="formula">x_text → Bottleneck(D→D/2)</text>
    <text x="275" y="212" text-anchor="middle" class="formula">→ Projection(D/2→3D)</text>
    <text x="275" y="229" text-anchor="middle" class="formula">+ Role Embeddings</text>
    <text x="275" y="246" text-anchor="middle" class="formula">→ (what, action, result)</text>
    <text x="275" y="265" text-anchor="middle" class="improvement">✓ Dropout 15% + Masking 10%</text>
    <text x="275" y="280" text-anchor="middle" class="improvement">✓ Contrastive Loss (τ=0.07)</text>
    
    <!-- Image Path with ViT -->
    <rect x="500" y="150" width="350" height="150" class="new" rx="3"/>
    <text x="675" y="175" text-anchor="middle" class="label">Image Path (ViT + Pyramids)</text>
    <text x="675" y="195" text-anchor="middle" class="formula">ViT(224×224) → Patches(14×14)</text>
    <text x="675" y="212" text-anchor="middle" class="formula">Pyramid: [768D, 384D, 192D]</text>
    <text x="675" y="229" text-anchor="middle" class="formula">→ Bottleneck(D→D/2)</text>
    <text x="675" y="246" text-anchor="middle" class="formula">→ Decompose → 3D</text>
    <text x="675" y="265" text-anchor="middle" class="improvement">✓ Multi-scale Features</text>
    <text x="675" y="280" text-anchor="middle" class="improvement">✓ ViT-Base-Patch16</text>
    
    <!-- Contrastive Loss Box -->
    <rect x="900" y="150" width="600" height="150" class="new" rx="3"/>
    <text x="1200" y="175" text-anchor="middle" class="label">Contrastive Alignment Loss</text>
    <text x="1200" y="200" text-anchor="middle" class="formula">text_feat = normalize(Bottleneck(x_text))</text>
    <text x="1200" y="217" text-anchor="middle" class="formula">image_feat = normalize(Bottleneck(x_image))</text>
    <text x="1200" y="234" text-anchor="middle" class="formula">logits = (text_feat @ image_feat^T) / τ</text>
    <text x="1200" y="251" text-anchor="middle" class="formula">L_CL = 0.5 * (CE(t→i) + CE(i→t))</text>
    <text x="1200" y="275" text-anchor="middle" class="improvement">✓ Learnable Temperature τ</text>
    <text x="1200" y="290" text-anchor="middle" class="improvement">✓ Shared Semantic Space</text>
  </g>
  
  <line x1="800" y1="320" x2="800" y2="370" class="arrow"/>
  
  <!-- ============ SECTION 2: DREAM GENERATOR (MoE) ============ -->
  <g id="dream-generator">
    <rect x="50" y="370" width="1500" height="380" class="expert" rx="5"/>
    <text x="800" y="395" text-anchor="middle" class="subtitle">2. Dream Generator - MoE (IMPROVED)</text>
    
    <!-- Noisy Top-K Gating -->
    <rect x="100" y="420" width="450" height="140" class="new" rx="3"/>
    <text x="325" y="445" text-anchor="middle" class="label">Noisy Top-K Gating</text>
    <text x="325" y="467" text-anchor="middle" class="formula">clean_logits = MLP(triplet)</text>
    <text x="325" y="484" text-anchor="middle" class="formula">noise = randn() * softplus(noise_net)</text>
    <text x="325" y="501" text-anchor="middle" class="formula">noisy = clean + noise * σ</text>
    <text x="325" y="518" text-anchor="middle" class="formula">weights = sparse_softmax(top_k(noisy))</text>
    <text x="325" y="540" text-anchor="middle" class="improvement">✓ Top-K=2 (Sparse Routing)</text>
    <text x="325" y="555" text-anchor="middle" class="improvement">✓ Load Balance Loss</text>
    
    <!-- Expert Architecture -->
    <rect x="600" y="420" width="900" height="140" class="new" rx="3"/>
    <text x="1050" y="445" text-anchor="middle" class="label">Transformer Experts (4 Experts)</text>
    <text x="750" y="467" text-anchor="middle" class="formula">Expert 0: Spatial</text>
    <text x="750" y="484" text-anchor="middle" class="formula">Expert 1: Temporal</text>
    <text x="970" y="467" text-anchor="middle" class="formula">Expert 2: Causal</text>
    <text x="970" y="484" text-anchor="middle" class="formula">Expert 3: Abstract</text>
    <text x="1300" y="467" text-anchor="middle" class="formula">Each: 2 Transformer Blocks</text>
    <text x="1300" y="484" text-anchor="middle" class="formula">8 Heads, Pre-Norm, GELU</text>
    <text x="1050" y="510" text-anchor="middle" class="formula">x → PosEmb → Transformer(x) → ProjectTriplet</text>
    <text x="1050" y="540" text-anchor="middle" class="improvement">✓ Replaced GRU with Transformers</text>
    <text x="1050" y="555" text-anchor="middle" class="improvement">✓ Cross-Expert Attention (8 heads)</text>
    
    <!-- Dream Sequence Generation -->
    <rect x="100" y="580" width="700" height="140" class="expert" rx="3"/>
    <text x="450" y="605" text-anchor="middle" class="label">Dream Sequence Generation</text>
    <text x="450" y="630" text-anchor="middle" class="formula">For each dream d in [1..num_dreams]:</text>
    <text x="450" y="650" text-anchor="middle" class="formula">  triplet_d = initial + offset_d</text>
    <text x="450" y="670" text-anchor="middle" class="formula">  For each expert e: dream_e = Expert_e(triplet_d)</text>
    <text x="450" y="690" text-anchor="middle" class="formula">  blended = Σ(weights[e] * dream_e)</text>
    <text x="450" y="710" text-anchor="middle" class="formula">Output: [num_dreams × dream_length × triplets]</text>
    
    <!-- Expert Regularization -->
    <rect x="850" y="580" width="650" height="140" class="new" rx="3"/>
    <text x="1175" y="605" text-anchor="middle" class="label">Expert Regularization</text>
    <text x="1175" y="630" text-anchor="middle" class="formula">importance = Σ(weights) / B</text>
    <text x="1175" y="650" text-anchor="middle" class="formula">load = mean(softmax(logits))</text>
    <text x="1175" y="670" text-anchor="middle" class="formula">L_balance = num_experts * Σ(importance * load)</text>
    <text x="1175" y="695" text-anchor="middle" class="improvement">✓ Prevents Expert Collapse</text>
    <text x="1175" y="710" text-anchor="middle" class="improvement">✓ Encourages Specialization</text>
  </g>
  
  <line x1="800" y1="750" x2="800" y2="800" class="arrow"/>
  
  <!-- ============ SECTION 3: GRAPH REASONER ============ -->
  <g id="graph-reasoner">
    <rect x="50" y="800" width="1500" height="400" class="graph" rx="5"/>
    <text x="800" y="825" text-anchor="middle" class="subtitle">3. Dream Graph Reasoner (IMPROVED)</text>
    
    <!-- Learned Edge Predictor -->
    <rect x="100" y="850" width="450" height="140" class="new" rx="3"/>
    <text x="325" y="875" text-anchor="middle" class="label">Learned Edge Predictor</text>
    <text x="325" y="897" text-anchor="middle" class="formula">edge_input = concat(node_i, node_j)</text>
    <text x="325" y="914" text-anchor="middle" class="formula">edge_logits = MLP(edge_input) → 4D</text>
    <text x="325" y="931" text-anchor="middle" class="formula">edge_type = softmax(edge_logits)</text>
    <text x="325" y="948" text-anchor="middle" class="formula">edge_emb = Σ(type_prob * type_emb)</text>
    <text x="325" y="970" text-anchor="middle" class="improvement">✓ 4 Edge Types: temporal, spatial,</text>
    <text x="325" y="985" text-anchor="middle" class="improvement">  causal, abstract</text>
    
    <!-- Graph Transformer Layer -->
    <rect x="600" y="850" width="900" height="140" class="new" rx="3"/>
    <text x="1050" y="875" text-anchor="middle" class="label">Graph Transformer Layer</text>
    <text x="1050" y="897" text-anchor="middle" class="formula">Q, K, V = Linear(nodes); EdgeBias = Linear(edges)</text>
    <text x="1050" y="914" text-anchor="middle" class="formula">scores = (Q@K^T)/√D + EdgeBias</text>
    <text x="1050" y="931" text-anchor="middle" class="formula">attn = softmax(masked(scores)) @ V</text>
    <text x="1050" y="948" text-anchor="middle" class="formula">out = nodes + attn; out = out + FFN(out)</text>
    <text x="1050" y="970" text-anchor="middle" class="improvement">✓ Edge-Aware Attention</text>
    <text x="1050" y="985" text-anchor="middle" class="improvement">✓ Pre-Norm + Residuals + GELU</text>
    
    <!-- Multi-Hop Reasoning -->
    <rect x="100" y="1010" width="700" height="160" class="graph" rx="3"/>
    <text x="450" y="1035" text-anchor="middle" class="label">Multi-Hop Reasoning (3 Hops)</text>
    <text x="450" y="1060" text-anchor="middle" class="formula">nodes, adjacency, edges = build_graph(dreams)</text>
    <text x="450" y="1080" text-anchor="middle" class="formula">For hop in [1..num_hops]:</text>
    <text x="450" y="1100" text-anchor="middle" class="formula">  nodes = GraphTransformer(nodes, edges, adj)</text>
    <text x="450" y="1120" text-anchor="middle" class="formula">  memory = GRU(nodes, prev_memory)</text>
    <text x="450" y="1140" text-anchor="middle" class="formula">  nodes = memory</text>
    <text x="450" y="1160" text-anchor="middle" class="formula">reasoning = mean(nodes) → Aggregator</text>
    
    <!-- Node Memory -->
    <rect x="850" y="1010" width="650" height="160" class="new" rx="3"/>
    <text x="1175" y="1035" text-anchor="middle" class="label">Node Memory (Recurrent)</text>
    <text x="1175" y="1060" text-anchor="middle" class="formula">h_t = GRU(updated_nodes_t, h_{t-1})</text>
    <text x="1175" y="1085" text-anchor="middle" class="formula">Maintains context across hops</text>
    <text x="1175" y="1110" text-anchor="middle" class="formula">Enables long-term reasoning</text>
    <text x="1175" y="1145" text-anchor="middle" class="improvement">✓ Persistent Node States</text>
    <text x="1175" y="1160" text-anchor="middle" class="improvement">✓ Better Causal Reasoning</text>
  </g>
  
  <line x1="800" y1="1200" x2="800" y2="1250" class="arrow"/>
  
  <!-- ============ SECTION 4: RL COMPONENTS ============ -->
  <g id="rl-components">
    <rect x="50" y="1250" width="1500" height="380" class="rl" rx="5"/>
    <text x="800" y="1275" text-anchor="middle" class="subtitle">4. RL Components (IMPROVED)</text>
    
    <!-- Multi-Component Rewards -->
    <rect x="100" y="1300" width="700" height="180" class="new" rx="3"/>
    <text x="450" y="1325" text-anchor="middle" class="label">Multi-Component Reward Model</text>
    <text x="450" y="1350" text-anchor="middle" class="formula">features = Extractor(concat(what, action, result))</text>
    <text x="450" y="1370" text-anchor="middle" class="formula">R_faithfulness = Head_1(features)</text>
    <text x="450" y="1387" text-anchor="middle" class="formula">R_coherence = Head_2(features)</text>
    <text x="450" y="1404" text-anchor="middle" class="formula">R_correctness = Head_3(features)</text>
    <text x="450" y="1421" text-anchor="middle" class="formula">R_creativity = Head_4(features)</text>
    <text x="450" y="1438" text-anchor="middle" class="formula">R_total = Σ(w_i * R_i), w = softmax(learnable)</text>
    <text x="450" y="1465" text-anchor="middle" class="improvement">✓ 4 Reward Components</text>
    
    <!-- PPO Trainer -->
    <rect x="850" y="1300" width="650" height="180" class="new" rx="3"/>
    <text x="1175" y="1325" text-anchor="middle" class="label">PPO Trainer</text>
    <text x="1175" y="1350" text-anchor="middle" class="formula">ratio = π_new(a|s) / π_old(a|s)</text>
    <text x="1175" y="1370" text-anchor="middle" class="formula">surr1 = ratio * A(s,a)</text>
    <text x="1175" y="1387" text-anchor="middle" class="formula">surr2 = clip(ratio, 1-ε, 1+ε) * A(s,a)</text>
    <text x="1175" y="1404" text-anchor="middle" class="formula">L_policy = -min(surr1, surr2)</text>
    <text x="1175" y="1421" text-anchor="middle" class="formula">L_value = MSE(V(s), returns)</text>
    <text x="1175" y="1438" text-anchor="middle" class="formula">A(s,a) = GAE(rewards, values, λ=0.95)</text>
    <text x="1175" y="1465" text-anchor="middle" class="improvement">✓ Clipped Objective (ε=0.2)</text>
    
    <!-- Policy & Value Networks -->
    <rect x="100" y="1500" width="700" height="100" class="rl" rx="3"/>
    <text x="450" y="1525" text-anchor="middle" class="label">Policy Network π_θ(a|s)</text>
    <text x="450" y="1550" text-anchor="middle" class="formula">state → Encoder → ActionValues(neighbors)</text>
    <text x="450" y="1570" text-anchor="middle" class="formula">probs = softmax(masked_logits)</text>
    <text x="450" y="1590" text-anchor="middle" class="formula">action ~ Categorical(probs)</text>
    
    <rect x="850" y="1500" width="650" height="100" class="rl" rx="3"/>
    <text x="1175" y="1525" text-anchor="middle" class="label">Value Network V_φ(s)</text>
    <text x="1175" y="1550" text-anchor="middle" class="formula">state → Encoder → ValueHead</text>
    <text x="1175" y="1570" text-anchor="middle" class="formula">V(s) = Linear(hidden) → scalar</text>
    <text x="1175" y="1590" text-anchor="middle" class="improvement">✓ Independent Baseline</text>
  </g>
  
  <line x1="800" y1="1630" x2="800" y2="1680" class="arrow"/>
  
  <!-- ============ SECTION 5: TRAINING IMPROVEMENTS ============ -->
  <g id="training-improvements">
    <rect x="50" y="1680" width="1500" height="320" class="new" rx="5"/>
    <text x="800" y="1705" text-anchor="middle" class="subtitle">5. Training Infrastructure (NEW)</text>
    
    <!-- Curriculum Learning -->
    <rect x="100" y="1730" width="450" height="140" class="new" rx="3"/>
    <text x="325" y="1755" text-anchor="middle" class="label">Curriculum Learning</text>
    <text x="325" y="1777" text-anchor="middle" class="formula">Stage 1: Core (1000 steps)</text>
    <text x="325" y="1794" text-anchor="middle" class="formula">Stage 2: Multi-Hop (2000 steps)</text>
    <text x="325" y="1811" text-anchor="middle" class="formula">Stage 3: Causal (3000 steps)</text>
    <text x="325" y="1828" text-anchor="middle" class="formula">Stage 4: Multimodal (5000 steps)</text>
    <text x="325" y="1855" text-anchor="middle" class="improvement">✓ Progressive Difficulty</text>
    
    <!-- Extended Context -->
    <rect x="600" y="1730" width="450" height="140" class="new" rx="3"/>
    <text x="825" y="1755" text-anchor="middle" class="label">ALiBi (Extended Context)</text>
    <text x="825" y="1777" text-anchor="middle" class="formula">bias[i,j] = (i - j) * slope_h</text>
    <text x="825" y="1794" text-anchor="middle" class="formula">slopes = 2^(-8/n), 2^(-16/n), ...</text>
    <text x="825" y="1811" text-anchor="middle" class="formula">attn = softmax(QK^T/√d + bias) @ V</text>
    <text x="825" y="1828" text-anchor="middle" class="formula">Context: 512 → 2048+ tokens</text>
    <text x="825" y="1855" text-anchor="middle" class="improvement">✓ No Retraining Needed</text>
    
    <!-- RoPE -->
    <rect x="1100" y="1730" width="400" height="140" class="new" rx="3"/>
    <text x="1300" y="1755" text-anchor="middle" class="label">RoPE (Rotary Embeddings)</text>
    <text x="1300" y="1777" text-anchor="middle" class="formula">θ = pos / base^(2i/d)</text>
    <text x="1300" y="1794" text-anchor="middle" class="formula">x_rot = [x1*cos-x2*sin,</text>
    <text x="1300" y="1811" text-anchor="middle" class="formula">         x1*sin+x2*cos, ...]</text>
    <text x="1300" y="1828" text-anchor="middle" class="formula">YaRN scaling: factor=2.0</text>
    <text x="1300" y="1855" text-anchor="middle" class="improvement">✓ Better Long-Range</text>
    
    <!-- SparseMax -->
    <rect x="100" y="1890" width="1400" height="80" class="new" rx="3"/>
    <text x="800" y="1915" text-anchor="middle" class="label">SparseMax Activation (Sparse Alternative to Softmax)</text>
    <text x="800" y="1940" text-anchor="middle" class="formula">output = max(0, x - τ) where τ chosen to Σ(output) = 1</text>
    <text x="800" y="1960" text-anchor="middle" class="improvement">✓ Sparse Outputs (many exact zeros) ✓ Better Interpretability</text>
  </g>
  
  <line x1="800" y1="2000" x2="800" y2="2050" class="arrow"/>
  
  <!-- ============ SECTION 6: OUTPUT DECODER ============ -->
  <g id="output-decoder">
    <rect x="50" y="2050" width="1500" height="160" class="component" rx="5"/>
    <text x="800" y="2075" text-anchor="middle" class="subtitle">6. Output Decoder</text>
    
    <rect x="100" y="2100" width="650" height="80" class="component" rx="3"/>
    <text x="425" y="2125" text-anchor="middle" class="label">Text Generation</text>
    <text x="425" y="2147" text-anchor="middle" class="formula">reasoning → Decoder → vocab_logits</text>
    <text x="425" y="2167" text-anchor="middle" class="formula">P(w_t|context) = softmax(W_out @ h_t)</text>
    
    <rect x="800" y="2100" width="650" height="80" class="component" rx="3"/>
    <text x="1125" y="2125" text-anchor="middle" class="label">Image Generation</text>
    <text x="1125" y="2147" text-anchor="middle" class="formula">reasoning → ImageDecoder → triplet</text>
    <text x="1125" y="2167" text-anchor="middle" class="formula">Output: (what, action, result) images</text>
  </g>
  
  <!-- ============ LEGEND ============ -->
  <g id="legend">
    <rect x="50" y="2250" width="1500" height="500" class="box" rx="5"/>
    <text x="800" y="2280" text-anchor="middle" class="subtitle">Architecture Summary and Parameters</text>
    
    <!-- Improvements Summary -->
    <text x="100" y="2320" class="label" font-weight="bold">✓ NEW IMPROVEMENTS (v2.0):</text>
    <text x="120" y="2345" class="note">• Contrastive alignment loss (CLIP-style) with projection bottleneck</text>
    <text x="120" y="2365" class="note">• Vision Transformer (ViT) with multi-scale feature pyramids</text>
    <text x="120" y="2385" class="note">• Noise robustness: 15% dropout + 10% token masking</text>
    <text x="120" y="2405" class="note">• Noisy Top-K gating (Switch Transformer) with load balancing</text>
    <text x="120" y="2425" class="note">• Transformer experts (replaced GRU) with cross-expert attention</text>
    <text x="120" y="2445" class="note">• Learned edge predictor (4 types: temporal, spatial, causal, abstract)</text>
    <text x="120" y="2465" class="note">• Graph Transformer with edge-aware attention and node memory</text>
    <text x="120" y="2485" class="note">• Multi-component rewards: faithfulness, coherence, correctness, creativity</text>
    <text x="120" y="2505" class="note">• PPO with clipped objective (ε=0.2) and GAE (λ=0.95)</text>
    <text x="120" y="2525" class="note">• Curriculum learning (4 stages: core→multi-hop→causal→multimodal)</text>
    <text x="120" y="2545" class="note">• ALiBi for extended context (512→2048+ tokens, no retraining)</text>
    <text x="120" y="2565" class="note">• RoPE with YaRN scaling for better long-range attention</text>
    <text x="120" y="2585" class="note">• SparseMax activation for sparse, interpretable outputs</text>
    
    <!-- Parameters -->
    <text x="900" y="2320" class="label" font-weight="bold">Key Parameters:</text>
    <text x="920" y="2345" class="formula">embedding_dim: 512 (or 768 for ViT)</text>
    <text x="920" y="2365" class="formula">num_dreams: 4 parallel sequences</text>
    <text x="920" y="2385" class="formula">dream_length: 5 steps per sequence</text>
    <text x="920" y="2405" class="formula">num_experts: 4 (Spatial, Temporal, Causal, Abstract)</text>
    <text x="920" y="2425" class="formula">moe_top_k: 2 (sparse routing)</text>
    <text x="920" y="2445" class="formula">graph_hops: 3 reasoning iterations</text>
    <text x="920" y="2465" class="formula">num_heads: 8 (attention layers)</text>
    <text x="920" y="2485" class="formula">edge_types: 4 learned relation types</text>
    <text x="920" y="2505" class="formula">ppo_clip: 0.2 (clipping threshold)</text>
    <text x="920" y="2525" class="formula">gae_lambda: 0.95 (advantage estimation)</text>
    <text x="920" y="2545" class="formula">contrastive_temp: 0.07 (temperature)</text>
    <text x="920" y="2565" class="formula">context_length: 2048 (with ALiBi)</text>
    <text x="920" y="2585" class="formula">curriculum_stages: 4 progressive stages</text>
    
    <!-- Color Legend -->
    <rect x="100" y="2620" width="30" height="20" class="component"/>
    <text x="140" y="2635" class="label">Input/Output</text>
    
    <rect x="300" y="2620" width="30" height="20" class="expert"/>
    <text x="340" y="2635" class="label">MoE Experts</text>
    
    <rect x="500" y="2620" width="30" height="20" class="graph"/>
    <text x="540" y="2635" class="label">Graph Reasoning</text>
    
    <rect x="750" y="2620" width="30" height="20" class="rl"/>
    <text x="790" y="2635" class="label">RL Components</text>
    
    <rect x="1000" y="2620" width="30" height="20" class="new"/>
    <text x="1040" y="2635" class="label">NEW Improvements</text>
    
    <!-- Data Flow -->
    <text x="100" y="2680" class="label" font-weight="bold">Data Flow:</text>
    <text x="120" y="2705" class="formula">Input → Tokenizer → Dream Generator (MoE) → Graph Reasoner → RL Learning → Output</text>
    <text x="120" y="2725" class="note">Training includes: Contrastive Loss + Load Balance Loss + Task Loss + RL Loss</text>
  </g>
  
  <!-- Version Info -->
  <text x="800" y="2770" text-anchor="middle" class="note">Version 2.0 - Complete Architecture with All Improvements</text>
  <text x="800" y="2790" text-anchor="middle" class="note">Generated: November 17, 2025</text>
</svg>
